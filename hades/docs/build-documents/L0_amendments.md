# L0_amendments.md  

**HADES Project Build Amendments**  
_Last Updated: 2025-01-31_  

---

## ğŸ“Œ Amendment #001 - Removing Manual Tiered Storage, Letting ArangoDB Handle It  

**Status:** âœ… Implemented  
**Implementation Progress:**  

- âœ… L3/L4 storage interfaces updated  
- âœ… RAID paths configured in L1_hardware.md  
- âœ… Performance monitoring added  

### ğŸ”¹ Summary of Change  

Originally, HADES implemented a **manual three-tier memory system (Elysium, Asphodel, Lethe)** to optimize knowledge storage and retrieval. **We are now shifting to ArangoDB's built-in optimization mechanisms** and letting it manage data transitions **dynamically**.

### ğŸ”¹ Implementation Plan

âœ… **Ensure collections are mounted correctly on RAID0 and RAID1.**  
âœ… **Modify `arangod.conf` settings to optimize caching & WAL.**  
âœ… **Monitor performance after deployment.**  

---

## ğŸ“Œ Amendment #002 - Expanding Model Hosting Beyond Ollama  

**Status:** âš ï¸ Partially Implemented  
**Remaining Work:**  

- âŒ vLLM/DeepSpeed integration in L2  
- âŒ Dynamic backend switching UI  
- âœ… Ollama remains primary host  

### ğŸ”¹ Summary of Change  

HADES will support **multiple model hosting backends** alongside **Ollama**, including:  
âœ… **DeepSpeed** for optimized large-model inference.  
âœ… **vLLM** for high-throughput batch inference.  

### ğŸ”¹ Implementation Plan  

âœ… **Modify Layer 2 to support backend switching dynamically.**  
âœ… **Update Fedora 41 installation instructions to include DeepSpeed & vLLM.**  
âœ… **Verify performance across different workloads and adjust as needed.**  

---

## ğŸ“Œ Amendment #003 - Separation of Judgment and Execution for Updates  

**Status:** âœ… Implemented  
**Implementation Evidence:**  

```python  
# L4_inference_layer_build.md  
class ValidationOrchestrator:  
    async def validate_update(self, data):  
        if not await self.judges.validate(data):  
            return False  
        return await self.storage.execute(data)  
```  

### ğŸ”¹ Summary of Change  

ModernBERT models (Embedding, Graph, Document) act as **Judges** to determine updates, but **they do not modify the database directly**. Instead, an **Execution Layer** performs updates **only if the Judge rules an update is necessary**.

### ğŸ”¹ Implementation Plan  

âœ… **Judges evaluate if an update is needed.**  
âœ… **Execution Layer performs database updates only when approved.**  
âœ… **This prevents unnecessary writes and improves efficiency.**  

---

## ğŸ“Œ Amendment #004 - Moving Embedding Model Operations to CPU  

**Status:** âœ… Implemented  
**Verification:**  

- âœ… CPU-bound tags in L4 inference layer  
- âœ… Weekly fine-tuning jobs configured  

### ğŸ”¹ Summary of Change  

All **embedding-related operations** in HADES will be **moved to CPU**, freeing **GPU resources for inference and reasoning models**.

### ğŸ”¹ Implementation Plan  

âœ… **Ensure embedding inference & fine-tuning run on CPU.**  
âœ… **Optimize ArangoDB indexing for CPU-based retrieval.**  
âœ… **Automate weekly fine-tuning on CPU to keep retrieval accurate.**  

---

## ğŸ“Œ Amendment #005 - Using ArangoDB TTL Collections Instead of Redis  

**Status:** âŒ Not Started  
**Blockers:**  

- Need TTL collection schema in L3  
- Cache expiration policies undefined  

### ğŸ”¹ Summary of Change  

HADES Judges will store **temporary learning signals & past judgments** inside **ArangoDBâ€™s TTL-based collections** instead of using **Redis**.

### ğŸ”¹ Implementation Plan  

âœ… **Create a TTL-based cache inside ArangoDB for temporary judge decisions.**  
âœ… **Avoid using Redis as an extra dependency.**  
âœ… **Ensure ArangoDBâ€™s cache is optimized for fast lookups.**  

---

## ğŸ“Œ Amendment #006 - Introducing a 4th Decoder Model for the HADES Frontend  

**Status:** âŒ Design Phase  
**Pending Tasks:**  

- â— Decoder integration point in L4  
- â— Performance benchmarks needed  

### ğŸ”¹ Summary of Change  

HADES requires an additional **4th decoder model** to act as the **frontend interface for all user interactions**.  

- This model will **interpret user input**, classify intent, and route requests appropriately.  
- It will integrate deeply into **Layers 5, 6, and 7** to **handle orchestration, routing, and presentation**.  
- It will also enable **self-aware ECL usage**, ensuring that context retrieval is optimized.

### ğŸ”¹ Why This is Necessary  

âœ… The **frontend model must dynamically determine when to use an ECL vs. standard retrieval.**  
âœ… **Prompt engineering** will allow users to interact with ECLs, triggering playbooks via chat.  
âœ… The model ensures **seamless context integration between InCA/ECL and ArangoDB**, maintaining up-to-date knowledge retrieval.

### ğŸ”¹ Implementation Plan  

âœ… **Embed the 4th decoder model into Layer 5 (Orchestration), Layer 6 (Routing), and Layer 7 (Presentation).**  
âœ… **Use prompt engineering to allow system-level commands like "Initiate ECL in this directory."**  
âœ… **Integrate the ECL Registry into ArangoDB to track active ECLs and keep it in sync with file system updates.**  
âœ… **Develop an automatic syncing mechanism to keep the ECL list updated without manual intervention.**  

---

## ğŸ“Œ Amendment #007 - Implementing InCA/ECL for Dynamic Knowledge Tracking  

**Status:** ğŸ”¥ Important (Enhances Long-Term Learning)  
**Date:** 2025-02-01  
**Author:** Project Architect  

### ğŸ”¹ Summary of Change  

The **InCA framework** (In-context Continual Learning Assisted by an External Continual Learner) will be used in HADES to enable dynamic, incremental learning.  

- **ECLs act as metadata-driven "masks"** that refine how knowledge is retrieved and updated, without retraining the model.  
- **Instead of applying ECLs to all knowledge**, only specific domains (like codebases) will have designated ECLs.  
- **The frontend model will dynamically decide when to use an ECL** vs. standard RAG retrieval.

### ğŸ”¹ Why This is Necessary  

âœ… **Ensures efficient knowledge tracking for specific domains.**  
âœ… **Prevents catastrophic forgetting while allowing incremental updates.**  
âœ… **Improves query performance by retrieving only the most relevant context dynamically.**  

### ğŸ”¹ Implementation Plan  

âœ… **Assign ECLs dynamically to specific directories and store metadata in ArangoDB.**  
âœ… **Develop a syncing mechanism that updates the ECL list whenever files in an ECL-tracked directory change.**  
âœ… **Modify query routing to check if an ECL exists before deciding how to retrieve knowledge.**  
âœ… **Enable user interaction via chat-based prompts for managing ECLs.**  

---

## ğŸ“Œ Build Documents That Require Updates  

### **1ï¸âƒ£ L5_Orchestration_Layer_Build.md**  

ğŸ”¹ **What Needs to Be Updated?**  

- Introduce **4th decoder model** to manage **playbooks for ECL setup**.  
- Implement **trigger-based execution**, allowing the model to **run system commands like "Initiate ECL in this directory."**  

---

### **2ï¸âƒ£ L6_Query_Presentation_Build.md**  

ğŸ”¹ **What Needs to Be Updated?**  

- Modify query routing logic to **check for active ECLs before running a RAG query.**  
- Introduce **a database-backed registry of all active ECLs, stored in ArangoDB**.  
- Implement **syncing between ECLs and file system updates**.  

---

### **3ï¸âƒ£ L7_UI_Sessions_Build.md**  

ğŸ”¹ **What Needs to Be Updated?**  

- Implement **natural language prompts that allow users to interact with the ECL system.**  
- Add **interactive chat-based commands to manage ECLs** (e.g., "List all active ECLs.").  
- Ensure the **frontend can display real-time ECL usage and query routing behavior**.  

---

ğŸ”¥ **These upgrades will make HADES fully dynamic, allowing it to manage and expand its own knowledge base recursively.** ğŸš€  
